{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross_Validation_SVM_Track1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whzm38hwNvsh"
      },
      "source": [
        "#Uralic Language Identification Task - VarDial2021 - Part 2\n",
        "\n",
        "This notebook contains the code developed by Team Phlyers to distinguish between 'target' and 'non-target' languages for the ULI shared task at VarDial2021.\n",
        "\n",
        "The first few blocks are needed to set up the directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBow2fzGh6iO",
        "outputId": "688025e1-3632-4550-d8fc-48fd21793fc4"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBClZawLh-gT",
        "outputId": "227888af-6781-42d9-fd7d-3d180d0822e6"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/ULI-VarDial2021"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/ULI-VarDial2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbYoGQYjOCkJ"
      },
      "source": [
        "This block loads the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx_6aakwh-TT"
      },
      "source": [
        "import json\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# The corpus is stored in a dictionary in json format\n",
        "# Dictionary format: {category:{language:[list of texts]}}\n",
        "with open('data.json') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "# Dataset is in the format of a tuple (category, lang, sentence)\n",
        "dataset = []\n",
        "\n",
        "for category in data:\n",
        "  for lang in data[category]:\n",
        "    for sentence in data[category][lang]:\n",
        "      dataset.append((category, lang, sentence))\n",
        "\n",
        "# Sentences are shuffled\n",
        "random.shuffle(dataset)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufH-Vit5OIio"
      },
      "source": [
        "We then perform cross-validation on a SVM classifier that is trained to distinguish 'target' from 'non-target' languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz8xb7ioOULK",
        "outputId": "2e242163-56ba-44c5-b0a1-869bb47e2810"
      },
      "source": [
        "# Create a vector with all the sentences, and a vector with all the categories\n",
        "\n",
        "X_train = [sentence for _, _, sentence in dataset]\n",
        "y_train = [category for category, _, _ in dataset]\n",
        "\n",
        "# Train a Support Vector Machine with cross-validation\n",
        "\n",
        "vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3,4), max_features=100000)\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "model = SGDClassifier(max_iter=7000)\n",
        "scores = cross_val_score(model, X_train, y_train, scoring='f1_macro')\n",
        "print('Results:')\n",
        "print(scores)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results:\n",
            "[0.99536094 0.99527404 0.99538954 0.99539333 0.99531734]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}