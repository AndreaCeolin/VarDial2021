{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Track1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpQsJLqS6viW"
      },
      "source": [
        "#Uralic Language Identification Task - VarDial2021 - Part 5\n",
        "\n",
        "This notebook contains the code developed by Team Phlyers for Track 1 and 2 of the ULI shared task at VarDial2021.\n",
        "\n",
        "The first few blocks are needed to set up the directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7xfXFhJ3wdE",
        "outputId": "1e310987-37f9-4aca-8ede-9a106283f3cf"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsfW8K9j3w2I",
        "outputId": "1dcb86d2-8e36-4419-93ca-de4ef4b54466"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/ULI-VarDial2021"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/ULI-VarDial2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB-OfaSZ8Oqh"
      },
      "source": [
        "This block contains the two classifiers we decided to use for the task (a SVM classifier to distinguish between 'target' and 'non-target' languages, and a NB classifier to distinguish among 'target' languages)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3nXSyF11Ema"
      },
      "source": [
        "import json\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def svm(train, eval):\n",
        "    # Vectorize training set\n",
        "    vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3,4), max_features=100000)\n",
        "    scaler = StandardScaler(with_mean=False)\n",
        "    X_train = vectorizer.fit_transform([sentence for key,sentence in train])\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    y_train = [key for key,sentence in train]\n",
        "    print('Rows x: ' + str(X_train.shape[0]))\n",
        "    print('Columns x: ' + str(X_train.shape[1]))\n",
        "    print('Labels y: ' + str(len(y_train)))\n",
        "    # Train a SVM classifier\n",
        "    model = SGDClassifier(max_iter=7000)\n",
        "    model.fit(X_train, y_train)\n",
        "    # Vectorize Evaluation\n",
        "    X_eval = vectorizer.transform([sentence for key, sentence in eval])\n",
        "    X_eval = scaler.transform(X_eval)\n",
        "    y_eval = [key for key,sentence in eval]\n",
        "    # Predict\n",
        "    ypred = model.predict(X_eval)\n",
        "    accuracy = f1_score(y_eval, ypred, average='macro')\n",
        "    # Calculate F-score globally and print F-score per category\n",
        "    print('F1_score:')\n",
        "    print(accuracy)\n",
        "    print('F1_score per category:')\n",
        "    print(f1_score(y_eval, ypred, average=None))\n",
        "    return list(ypred)\n",
        "\n",
        "def mnb(train, submission, alpha, range, min):\n",
        "    # Vectorize training set\n",
        "    vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(range), min_df=min, sublinear_tf=True)\n",
        "    X_train = vectorizer.fit_transform([sentence for key,sentence in train])\n",
        "    y_train = [key for key,sentence in train]\n",
        "    print('Rows x: ' + str(X_train.shape[0]))\n",
        "    print('Columns x: ' + str(X_train.shape[1]))\n",
        "    print('Labels y: ' + str(len(y_train)))\n",
        "    # Train a Naive Bayes classifier\n",
        "    model = MultinomialNB(alpha=alpha)\n",
        "    model.fit(X_train, y_train)\n",
        "    print('Model fitted')\n",
        "    # Vectorize Evaluation\n",
        "    X_test = vectorizer.transform(submission)\n",
        "    print('Test set vectorized.')\n",
        "    # Predict\n",
        "    ypred = model.predict(X_test)\n",
        "    # Calculate F-score globally and print F-score per category\n",
        "    print('Predictions have been made.')\n",
        "    return list(ypred)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJNYCCoU9A2l"
      },
      "source": [
        "This block loads the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95g_fSSP9Eh5",
        "outputId": "49b0af80-625c-4347-dce3-e48124940c48"
      },
      "source": [
        "# The corpus is stored in a dictionary in json format\n",
        "# Dictionary format: {category:{language:[list of texts]}}\n",
        "with open('data.json') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "# Dataset is in the format of a tuple (category, lang, sentence)\n",
        "dataset = []\n",
        "\n",
        "for category in data:\n",
        "  for lang in data[category]:\n",
        "    for sentence in data[category][lang]:\n",
        "      dataset.append((category, lang, sentence))\n",
        "\n",
        "print(\"Length of the dataset:\")\n",
        "print(len(dataset))\n",
        "\n",
        "random.shuffle(dataset)\n",
        "\n",
        "# Split the data in a train and test set\n",
        "train_list = dataset[len(dataset)//5:]\n",
        "eval_list = dataset[:len(dataset)//5]\n",
        "\n",
        "\n",
        "training = [(category, sentence) for category, _, sentence in train_list]\n",
        "eval = [(category, sentence) for category, _, sentence in eval_list]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the dataset:\n",
            "1391043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WlnKmoG9NhE"
      },
      "source": [
        "This block runs the SVM on the data to single out 'target' languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH3IBCVD9AcK",
        "outputId": "bd005cf8-86ca-4be3-ffac-53344daf5933"
      },
      "source": [
        "y_eval_pred = svm(training, eval)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rows x: 1112835\n",
            "Columns x: 100000\n",
            "Labels y: 1112835\n",
            "F1_score:\n",
            "0.9954597740791868\n",
            "F1_score per category:\n",
            "[0.99580082 0.99511873]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNBnZped9hUL"
      },
      "source": [
        "This block runs the MNB on the singled out sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIL7hIz3CszO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fbc4a9-f23b-4b48-d1c8-a7691e083da9"
      },
      "source": [
        "#extract (language,sentence) for all the target languages in the training dataset\n",
        "training_ural = [(language,sentence) for category, language, sentence in train_list if category == \"UR\"]\n",
        "\n",
        "#extract all sentences in the eval dataset which are predicted to be on target\n",
        "eval_ural = []\n",
        "\n",
        "for predicted, instance in zip(y_eval_pred, eval_list):\n",
        "  if predicted == \"UR\":\n",
        "    category, language, sentence = instance\n",
        "    eval_ural.append(sentence)\n",
        "\n",
        "\n",
        "#extract the true labels of the target languages, while everything else is assigned the default category label 'NA'\n",
        "true_labels = []\n",
        "\n",
        "for category, language, sentence in eval_list:\n",
        "  if category == \"UR\":\n",
        "    true_labels.append(language)\n",
        "  else:\n",
        "    true_labels.append(category)\n",
        "\n",
        "\n",
        "y_ural_predict = mnb(training_ural, eval_ural, 0.0000001, (3,5), 0.000001)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rows x: 517288\n",
            "Columns x: 1539060\n",
            "Labels y: 517288\n",
            "Model fitted\n",
            "Test set vectorized.\n",
            "Predictions have been made.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNhJCLtzHZh4"
      },
      "source": [
        "Combine the predictions of the two classifiers, and calculate accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFFhlwx3Hcso",
        "outputId": "42b426c2-d674-4b36-c4ad-8f62854fec67"
      },
      "source": [
        "predicted_labels = []\n",
        "for prediction in y_eval_pred:\n",
        "  if prediction == \"UR\":\n",
        "    # if the prediction of the SVM classifier is that of a target language, retrieve the language label from the MNB predictions\n",
        "    predicted_labels.append(y_ural_predict.pop(0))\n",
        "  else:\n",
        "    # if the prediction of the SVM classifier is that of a non-target language, then predict 'NA'\n",
        "    predicted_labels.append(prediction)\n",
        "\n",
        "print(\"Macro F1:\")\n",
        "print(f1_score(true_labels, predicted_labels, average=\"macro\"))\n",
        "print(\"Micro F1:\")\n",
        "print(f1_score(true_labels, predicted_labels, average=\"micro\"))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Macro F1:\n",
            "0.9141107943083907\n",
            "Micro F1:\n",
            "0.9893029675638372\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}