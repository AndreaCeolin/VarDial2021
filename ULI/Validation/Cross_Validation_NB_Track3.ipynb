{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross_Validation_NB_Track3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWOoWC5Z1R_3"
      },
      "source": [
        "#Uralic Language Identification Task - VarDial2021 - Part 4\n",
        "\n",
        "This notebook contains the code developed by Team Phlyers for Track 3 of the ULI shared task at VarDial2021.\n",
        "\n",
        "The first few blocks are needed to set up the directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBow2fzGh6iO",
        "outputId": "44af138f-40b7-41ea-edce-e79f9580859e"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBClZawLh-gT",
        "outputId": "54f7b670-e8c3-42e5-8c29-e6fba4ba2528"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/ULI-VarDial2021"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/ULI-VarDial2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J9XlzkH1etl"
      },
      "source": [
        "This block loads the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx_6aakwh-TT"
      },
      "source": [
        "import json\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# The corpus is stored in a dictionary in json format\n",
        "# Dictionary format: {category:{language:[list of texts]}}\n",
        "with open('data.json') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "# Dataset is in the format of a tuple (category, lang, sentence)\n",
        "dataset = []\n",
        "\n",
        "for category in data:\n",
        "  for lang in data[category]:\n",
        "    for sentence in data[category][lang]:\n",
        "      dataset.append((category, lang, sentence))\n",
        "\n",
        "# Sentences are shuffled\n",
        "random.shuffle(dataset)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSBD_Xyy1pU0"
      },
      "source": [
        "We then perform cross-validation on a NB classifier that is trained to distinguish among all languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqCTN-fM1xTZ",
        "outputId": "1f2e2b0f-4baf-4254-aa08-495cb4f82af9"
      },
      "source": [
        "# Create a vector with all the sentences, and a vector with all the languages\n",
        "\n",
        "X_train = [sentence for category, _, sentence in dataset]\n",
        "y_train = [language for category, language, _ in dataset]\n",
        "\n",
        "# Train a Multinomial Naive Bayes model with cross-validation\n",
        "\n",
        "vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(5,5), min_df=0.00001, sublinear_tf=True)\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "model = MultinomialNB(alpha=0.0000001)\n",
        "scores = cross_val_score(model, X_train, y_train, scoring='f1_macro')\n",
        "print('Results:')\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results:\n",
            "[0.95188679 0.9493759  0.94861411 0.95050705 0.95223802]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}